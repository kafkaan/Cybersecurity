# Directory & File Fuzzing

### <mark style="color:blue;">ğŸ” Objectif</mark>

DÃ©couvrir **rÃ©pertoires, fichiers et endpoints cachÃ©s** dâ€™une application web (backups, config, vieux scripts, panels admin, environnements de dev) qui peuvent divulguer des infos sensibles ou offrir des points dâ€™entrÃ©e.

***

### <mark style="color:blue;">ğŸ§­ Pourquoi câ€™est important</mark>

* Permet dâ€™identifier des **ressources non rÃ©fÃ©rencÃ©es** (fichiers .bak, config, logs).
* Ces ressources manquent souvent de protections et peuvent faciliter une compromission.
* Donne une vue complÃ¨te de la **surface dâ€™attaque** pour un audit ou pentest.

***

### <mark style="color:blue;">ğŸ§° MÃ©thode gÃ©nÃ©rale</mark>

1. Choisir / prÃ©parer une **wordlist** (liste de noms de dossiers/fichiers).
2. Lancer un outil de content discovery (ex. `ffuf`, `gobuster`, `feroxbuster`).
3. Analyser les **codes HTTP**, tailles et rÃ©ponses textuelles pour repÃ©rer les ressources valides.
4. Affiner (extensions, chemins rÃ©cursifs, exclusions) et **valider** manuellement les dÃ©couvertes.

***

### <mark style="color:blue;">ğŸ”‘ Wordlists (essentielles)</mark>

* **SecLists** (repository rÃ©fÃ©rence) â€” souvent installÃ©e sous `/usr/share/seclists/` sur les distro pentest.
  * `Discovery/Web-Content/common.txt` â€” bon dÃ©marrage gÃ©nÃ©ral
  * `Discovery/Web-Content/directory-list-2.3-medium.txt` â€” liste medium pour dossiers
  * `Discovery/Web-Content/raft-large-directories.txt` â€” large, explorations profondes
  * `Discovery/Web-Content/big.txt` â€” trÃ¨s volumineuse (fais attention au temps)
* Astuce : adaptes les listes au contexte (CMS, WordPress, frameworks, langues).

***

### <mark style="color:blue;">âš™ï¸ Exemple avec</mark> <mark style="color:blue;"></mark><mark style="color:blue;">**ffuf**</mark> <mark style="color:blue;"></mark><mark style="color:blue;">(principes & flags courants)</mark>

#### <mark style="color:green;">Commande basique â€” directory fuzzing</mark>

{% code fullWidth="true" %}
```
ffuf -w /usr/share/seclists/Discovery/Web-Content/directory-list-2.3-medium.txt -u http://IP:PORT/FUZZ
```
{% endcode %}

* `-w` : chemin du wordlist
* `-u` : URL, `FUZZ` = placeholder qui sera remplacÃ©

#### <mark style="color:green;">Commande â€” file fuzzing avec extensions</mark>

```
ffuf -w /usr/share/seclists/Discovery/Web-Content/common.txt -u http://IP:PORT/w2ksvrus/FUZZ -e .php,.html,.txt,.bak,.js -v
```

* `-e` : tester plusieurs extensions (.php, .html, ...)
* `-v` : verbose (plus dâ€™info)

#### InterprÃ©ter la sortie

* **Status 200** â†’ ressource trouvÃ©e (page valide).
* **Status 301/302** â†’ redirection (peut indiquer un rÃ©pertoire ou ressource dÃ©placÃ©e).
* **Status 403** â†’ accÃ¨s refusÃ© (possible ressource protÃ©gÃ©e mais existante).
* **Size / Words / Lines** : utile pour repÃ©rer rÃ©sultats anormaux (ex. page trÃ¨s courte = possible fichier intÃ©ressant).
*   Exemple de rÃ©sultat :

    ```
    dblclk.html [Status: 200, Size: 111] -> http://IP:PORT/w2ksvrus/dblclk.html
    ```

***

### <mark style="color:blue;">ğŸ§¾ Fuzzing de fichiers â€” bonnes pratiques</mark>

* Teste des **extensions pertinentes** pour le site (ex: .php pour PHP, .aspx pour ASP.NET).
* Lance dâ€™abord des listes **courtes** puis Ã©largis si rien.
* Utilise des **threads** raisonnables (`-t`) pour ne pas DDoS la cible par erreur.
* Filtre les **faux positifs** (pages 404 custom avec code 200 â€” comparer size & pattern).
* Suis la **lÃ©galitÃ© / autorisation** : ne fuzz que des targets pour lesquels tu as la permission.

***

### <mark style="color:blue;">ğŸ› ï¸ Outils courants pour directory/file fuzzing</mark>

* `ffuf` (Go) â€” flexible, rapide, trÃ¨s utilisÃ© pour dossiers/fichiers et paramÃ¨tres.
* `gobuster` (Go) â€” simple & rapide pour dÃ©couverte de contenu et vhosts.
* `feroxbuster` (Rust) â€” scans rÃ©cursifs performants (forced browsing).
* `wfuzz` / `wenum` (Python) â€” puissant pour fuzz paramÃ¨tres et custom payloads.

***

### <mark style="color:blue;">âš ï¸ PiÃ¨ges & erreurs courantes</mark>

* **Custom 404** qui renvoie 200 â†’ gÃ©nÃ©rer beaucoup de faux positifs : comparer `Size`/patterns.
* **Utiliser des wordlists trop grandes** sans ciblage â†’ long & bruyant.
* **Ignorer redirections** : 301/302 peuvent indiquer panels ou URL finales importantes.
* **Ne pas vÃ©rifier manuellement** : toujours valider les dÃ©couvertes via navigateur ou curl.

***

## <mark style="color:red;">Recursive Fuzzing</mark>

### <mark style="color:blue;">ğŸ¯ Objectif</mark>

Explorer automatiquement **les arborescences profondes** dâ€™une appli web pour trouver des rÃ©pertoires et fichiers cachÃ©s sans avoir Ã  lancer manuellement chaque niveau.

***

### <mark style="color:blue;">ğŸ” Principe en 3 Ã©tapes</mark>

1. **Fuzz initial** : on lance le fuzzer sur la racine (ex. `http://IP:PORT/FUZZ`) avec une wordlist.
2. **DÃ©couverte & expansion** : quand un rÃ©pertoire est trouvÃ© (souvent `301`), le fuzzer crÃ©e une nouvelle branche `http://IP:PORT/dir/` et relance le fuzz sur `.../dir/FUZZ`.
3. **ItÃ©ration** : rÃ©pÃ©tition jusquâ€™Ã  atteindre la profondeur maximale ou plus de nouveaux rÃ©pertoires.

Image mentale : lâ€™arbre dont la racine est `/`, chaque dossier dÃ©couvert devient une nouvelle branche Ã  explorer.

***

### <mark style="color:blue;">âœ… Pourquoi lâ€™utiliser</mark>

* **EfficacitÃ©** : automatise lâ€™exploration de structures profondes.
* **ExhaustivitÃ©** : rÃ©duit le risque de rater du contenu non liÃ© Ã  la racine.
* **Gain de temps** : Ã©vite les manipulations manuelles rÃ©pÃ©titives.
* **ScalabilitÃ©** : utile sur de grands sites complexes.

***

### <mark style="color:blue;">ğŸ› ï¸ Exemple (ffuf) â€” options utiles</mark>

Commande de base (concept) :

{% code overflow="wrap" fullWidth="true" %}
```shellscript
ffuf -w /usr/share/seclists/Discovery/Web-Content/directory-list-2.3-medium.txt -ic -u http://94.237.52.235:32485/recursive_fuzz/FUZZ -e .html -recursion
```
{% endcode %}

Flags importants :

* `-recursion` : active lâ€™exploration rÃ©cursive.
* `-recursion-depth N` : limite la profondeur Ã  N (ex: `-recursion-depth 2`).
* `-rate N` : limite le nombre de requÃªtes par seconde (ex: `-rate 500`).
* `-timeout X` : timeout des requÃªtes.
* `-ic` : ignore les lignes commentÃ©es (`#`) dans la wordlist.
* `-e .php,.html,.txt` : tester plusieurs extensions.
* `-t N` / `-threads` : nombre de threads (attention Ã  la charge serveur).

***

### <mark style="color:blue;">ğŸ§¾ InterprÃ©tation des rÃ©sultats</mark>

* **301 / 302** â†’ souvent un dossier (redirection vers `.../dir/`).
* **200** â†’ fichier existant (page valide).
* **403** â†’ ressource existante mais protÃ©gÃ©e (intÃ©ressant).
* **Size / Words / Lines** : trier par taille pour repÃ©rer anomalies / flags (fichiers courts contenant `HTB{...}`).

Exemple de sortie utile :

```
[Status: 301] http://IP:PORT/level1 -> ajoute job pour /level1/FUZZ
[Status: 200] http://IP:PORT/level1/index.html -> potentielle page intÃ©ressante
```

***

### <mark style="color:blue;">ğŸ§­ StratÃ©gie pratique rapide</mark>

1. Lancer recursion sur `/recursive_fuzz/` avec `-recursion-depth 2` et un rate raisonnable.
2. RepÃ©rer les `301` â†’ laisser ffuf crÃ©er les jobs.
3. Sur les branches avec `200`, relancer un fuzz ciblÃ© (extensions, wordlists plus fines).
4. Trier rÃ©sultats par `Status` puis `Size` pour isoler fichiers courts qui pourraient contenir la flag (`HTB{...}`).
5. Valider manuellement via navigateur ou `curl`.

***
